{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f41453-6c4e-4de4-8b5e-f0152714c263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Move the image tensors to the device\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m image_tensors \u001b[38;5;241m=\u001b[39m [image\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_tensors]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Resnet model\u001b[39;00m\n\u001b[1;32m     73\u001b[0m resnet \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 70\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Move the image tensors to the device\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m image_tensors \u001b[38;5;241m=\u001b[39m [\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m image_tensors]\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Resnet model\u001b[39;00m\n\u001b[1;32m     73\u001b[0m resnet \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mresnet18(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import os.path\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torchvision.io as io\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import ImageReadMode \n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 32\n",
    "num_classes = 4\n",
    "num_epochs = 10\n",
    "\n",
    "def label_images_in_directories(main_directory):\n",
    "    label_names = []\n",
    "    image_files = []\n",
    "    for directory in os.listdir(main_directory):\n",
    "        sub_directory = os.path.join(main_directory, directory)\n",
    "        if os.path.isdir(sub_directory):\n",
    "            for filename in os.listdir(sub_directory):\n",
    "                image_file = os.path.join(sub_directory, filename)\n",
    "                if os.path.isfile(image_file) and filename.endswith(\".jpg\"):\n",
    "                    label_names.append(directory)\n",
    "                    image_files.append(image_file)\n",
    "\n",
    "    # image_tensors = [torchvision.io.read_image(image, mode=ImageReadMode.UNCHANGED).to(torch.float32)/255 for image in image_files]\n",
    "    image_tensors = [torchvision.io.read_image(image, mode=ImageReadMode.UNCHANGED).to(torch.float32) for image in image_files]\n",
    "    # image_tensors = [plt.imread(image).astype(float) / 255 for image in image_files]\n",
    "    nr_of_images = len(image_tensors)\n",
    "\n",
    "    return label_names, image_tensors\n",
    "\n",
    "train_dir = \"../data/Train\"\n",
    "label_names, image_tensors = label_images_in_directories(train_dir)\n",
    "\n",
    "test_dir = \"../data/Test\"\n",
    "label_names, image_tensors = label_images_in_directories(test_dir)\n",
    "\n",
    "# Define the transformations before entering the neural network\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),  # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with resnet values\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Create DataLoaders for managing the data batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Move the image tensors to the device\n",
    "image_tensors = [image.to(device) for image in image_tensors]\n",
    "\n",
    "# Resnet model\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Move the model's parameters to the same device\n",
    "resnet.load_state_dict(resnet.state_dict())\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Change the number of output features in the last fully connected layer\n",
    "num_features = resnet.fc.in_features\n",
    "resnet.fc = nn.Linear(num_features, num_classes)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "summary(resnet.to(device), input_size=(3,image_size,image_size))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=0.0001, momentum=0.9)\n",
    "# optimizer = torch.optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
    "\n",
    "#6. Train the model\n",
    "totalLoss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    losses = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_acc = (train_correct / len(train_dataset))*100\n",
    "    totalLoss.append(sum(losses)/len(train_dataset))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# 7. Evaluate the model\n",
    "resnet.eval()  # Set the model to evaluation mode\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)      \n",
    "        \n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = 100 * total_correct / total_samples\n",
    "print(f\"Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Save model\n",
    "torch.save(resnet.state_dict(), \"model_apple_resnet.pth\")\n",
    "\n",
    "data = {\n",
    "    \"Image Resize\": str(image_size)+\"*\"+str(image_size),\n",
    "    \"Epochs\": num_epochs,\n",
    "    \"Train Accuracy\": train_acc,\n",
    "    \"Test Accuracy\": test_acc,\n",
    "    \"Dataset use\": os.path.basename(train_dir),\n",
    "    \"Model type\": \"resnet18\"\n",
    "}\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.isfile(\"model_data.csv\"):\n",
    "    existing_data = pd.read_csv(\"model_data.csv\")\n",
    "    new_data = pd.concat([existing_data, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "\n",
    "else:\n",
    "    new_data = pd.DataFrame(data, index=[0])\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "new_data.to_csv(\"model_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlabel='Epoch', ylabel='Loss', title=\"Training Loss\")\n",
    "\n",
    "plt.plot(totalLoss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad32c47-78a2-4708-be37-e90b431a6909",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
